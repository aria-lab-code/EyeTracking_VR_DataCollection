{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d65539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc9e59d",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9275e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "train_data_directory = \"../EyeTrackingTest/Data/Train\"\n",
    "for file in os.listdir(train_data_directory):\n",
    "    dataframes.append(pd.read_csv(os.path.join(train_data_directory, file), delimiter=\",\").iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f93b5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time(100ns)</th>\n",
       "      <th>time_stamp(ms)</th>\n",
       "      <th>frame</th>\n",
       "      <th>gaze_direct_L.x</th>\n",
       "      <th>gaze_direct_L.y</th>\n",
       "      <th>gaze_direct_L.z</th>\n",
       "      <th>gaze_direct_R.x</th>\n",
       "      <th>gaze_direct_R.y</th>\n",
       "      <th>gaze_direct_R.z</th>\n",
       "      <th>forward.x</th>\n",
       "      <th>forward.y</th>\n",
       "      <th>forward.z</th>\n",
       "      <th>label.x</th>\n",
       "      <th>label.y</th>\n",
       "      <th>label.z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>638000597804996743</td>\n",
       "      <td>40413</td>\n",
       "      <td>560</td>\n",
       "      <td>-0.023819</td>\n",
       "      <td>0.115951</td>\n",
       "      <td>0.992966</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>0.111084</td>\n",
       "      <td>0.993652</td>\n",
       "      <td>0.013144</td>\n",
       "      <td>0.088526</td>\n",
       "      <td>0.995987</td>\n",
       "      <td>0.013144</td>\n",
       "      <td>0.088526</td>\n",
       "      <td>0.995987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>638000597805076741</td>\n",
       "      <td>40421</td>\n",
       "      <td>560</td>\n",
       "      <td>-0.023819</td>\n",
       "      <td>0.116440</td>\n",
       "      <td>0.992905</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>0.109711</td>\n",
       "      <td>0.993805</td>\n",
       "      <td>0.013144</td>\n",
       "      <td>0.088526</td>\n",
       "      <td>0.995987</td>\n",
       "      <td>0.013634</td>\n",
       "      <td>0.088512</td>\n",
       "      <td>0.995982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>638000597805166743</td>\n",
       "      <td>40430</td>\n",
       "      <td>561</td>\n",
       "      <td>-0.023788</td>\n",
       "      <td>0.116440</td>\n",
       "      <td>0.992905</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>0.109009</td>\n",
       "      <td>0.993912</td>\n",
       "      <td>0.013634</td>\n",
       "      <td>0.088512</td>\n",
       "      <td>0.995982</td>\n",
       "      <td>0.013643</td>\n",
       "      <td>0.088508</td>\n",
       "      <td>0.995982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>638000597805246741</td>\n",
       "      <td>40438</td>\n",
       "      <td>562</td>\n",
       "      <td>-0.023560</td>\n",
       "      <td>0.115784</td>\n",
       "      <td>0.992981</td>\n",
       "      <td>0.016022</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.993866</td>\n",
       "      <td>0.013643</td>\n",
       "      <td>0.088508</td>\n",
       "      <td>0.995982</td>\n",
       "      <td>0.013599</td>\n",
       "      <td>0.088151</td>\n",
       "      <td>0.996014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>638000597805326743</td>\n",
       "      <td>40446</td>\n",
       "      <td>563</td>\n",
       "      <td>-0.023300</td>\n",
       "      <td>0.115921</td>\n",
       "      <td>0.992981</td>\n",
       "      <td>0.014969</td>\n",
       "      <td>0.108475</td>\n",
       "      <td>0.993973</td>\n",
       "      <td>0.013599</td>\n",
       "      <td>0.088151</td>\n",
       "      <td>0.996014</td>\n",
       "      <td>0.013599</td>\n",
       "      <td>0.088151</td>\n",
       "      <td>0.996014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          time(100ns)  time_stamp(ms)  frame  gaze_direct_L.x  \\\n",
       "0  638000597804996743           40413    560        -0.023819   \n",
       "1  638000597805076741           40421    560        -0.023819   \n",
       "2  638000597805166743           40430    561        -0.023788   \n",
       "3  638000597805246741           40438    562        -0.023560   \n",
       "4  638000597805326743           40446    563        -0.023300   \n",
       "\n",
       "   gaze_direct_L.y  gaze_direct_L.z  gaze_direct_R.x  gaze_direct_R.y  \\\n",
       "0         0.115951         0.992966         0.016953         0.111084   \n",
       "1         0.116440         0.992905         0.017181         0.109711   \n",
       "2         0.116440         0.992905         0.015930         0.109009   \n",
       "3         0.115784         0.992981         0.016022         0.109375   \n",
       "4         0.115921         0.992981         0.014969         0.108475   \n",
       "\n",
       "   gaze_direct_R.z  forward.x  forward.y  forward.z   label.x   label.y  \\\n",
       "0         0.993652   0.013144   0.088526   0.995987  0.013144  0.088526   \n",
       "1         0.993805   0.013144   0.088526   0.995987  0.013634  0.088512   \n",
       "2         0.993912   0.013634   0.088512   0.995982  0.013643  0.088508   \n",
       "3         0.993866   0.013643   0.088508   0.995982  0.013599  0.088151   \n",
       "4         0.993973   0.013599   0.088151   0.996014  0.013599  0.088151   \n",
       "\n",
       "    label.z  \n",
       "0  0.995987  \n",
       "1  0.995982  \n",
       "2  0.995982  \n",
       "3  0.996014  \n",
       "4  0.996014  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for j in range(len(dataframes)):\n",
    "    df = dataframes[j]\n",
    "    labelx = []\n",
    "    labely = []\n",
    "    labelz = []\n",
    "    for i in range(df.shape[0] - 1):\n",
    "        label_row = df.iloc[i + 1]\n",
    "        labelx.append(label_row[\"forward.x\"])\n",
    "        labely.append(label_row[\"forward.y\"])\n",
    "        labelz.append(label_row[\"forward.z\"])\n",
    "\n",
    "    df = df.iloc[:-1, :]\n",
    "    df[\"label.x\"] = labelx\n",
    "    df[\"label.y\"] = labely\n",
    "    df[\"label.z\"] = labelz\n",
    "    dataframes[j] = df\n",
    "\n",
    "dataframes[0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f885933",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_size = float('inf')\n",
    "for df in dataframes:\n",
    "    if df.shape[0] < min_size:\n",
    "        min_size = df.shape[0]\n",
    "\n",
    "for df in dataframes:\n",
    "    df = df[:min_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ac7c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7200, 9, 9]) torch.Size([7200, 9, 3])\n"
     ]
    }
   ],
   "source": [
    "X_series = []\n",
    "y_series = []\n",
    "for df in dataframes:\n",
    "    X = df.iloc[:, 3:-3].to_numpy()\n",
    "    y = df.iloc[:, -3:].to_numpy()\n",
    "    \n",
    "    X = Variable(torch.Tensor(X))\n",
    "    y = Variable(torch.Tensor(y))\n",
    "    \n",
    "    X = torch.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
    "    X_series.append(X)\n",
    "    y_series.append(y)\n",
    "X_series = torch.cat(X_series, dim=1)\n",
    "y_series = torch.stack(y_series, dim=1)\n",
    "print(X_series.shape, y_series.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c160961",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebfae681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size=3, hidden_size=9):\n",
    "        super(CustomLSTM, self).__init__()\n",
    "        self.num_classes = output_size\n",
    "        self.num_layers = 1\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden_size, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, self.num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, h_0=None, c_0=None):\n",
    "        if h_0 is None:\n",
    "            h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(torch.device(\"cuda\"))\n",
    "        if c_0 is None:\n",
    "            c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(torch.device(\"cuda\"))\n",
    "        \n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0))\n",
    "        _hn = hn.view(-1, self.hidden_size)\n",
    "        out = self.fc(_hn)\n",
    "        return out, hn, cn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ba27ba",
   "metadata": {},
   "source": [
    "## Training Loop and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9767714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    losses = []\n",
    "    for j in range(X.shape[1]):\n",
    "        instance = X[0:1, j:j+1, :]\n",
    "        hn = None\n",
    "        cn = None\n",
    "        for i in range(6000):\n",
    "            pred, hn, cn = model(instance, hn, cn)\n",
    "            pred = nn.functional.normalize(pred)\n",
    "            cur_loss = criterion(pred, y[i:i+1, j])\n",
    "            loss += cur_loss\n",
    "            losses.append(cur_loss.item())\n",
    "            \n",
    "            if i < 5999:\n",
    "                l_pred = nn.functional.normalize(torch.reshape(X[i+1,j:j+1,6:9] + X[i+1,j:j+1,0:3] - pred[0], (1,3)))\n",
    "                r_pred = nn.functional.normalize(torch.reshape(X[i+1,j:j+1,6:9] + X[i+1,j:j+1,3:6] - pred[0], (1,3)))\n",
    "                instance = torch.reshape(torch.cat((l_pred, r_pred, pred), axis=1), (1,1,9))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c956ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, X, y, criterion, device):\n",
    "    model.eval()\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    losses = []\n",
    "    for j in range(X.shape[1]):\n",
    "        instance = X[0:1, j:j+1, :]\n",
    "        hn = None\n",
    "        cn = None\n",
    "        for i in range(X.shape[0]):\n",
    "            pred, hn, cn = model(instance, hn, cn)\n",
    "            pred = nn.functional.normalize(pred)\n",
    "            loss = criterion(pred, y[i:i+1, j])\n",
    "            if i >= 6000:\n",
    "                losses.append(loss.item())\n",
    "            if i < X.shape[0] - 1:\n",
    "                l_pred = nn.functional.normalize(torch.reshape(X[i+1,j:j+1,6:9] + X[i+1,j:j+1,0:3] - pred[0], (1,3)))\n",
    "                r_pred = nn.functional.normalize(torch.reshape(X[i+1,j:j+1,6:9] + X[i+1,j:j+1,3:6] - pred[0], (1,3)))\n",
    "                instance = torch.reshape(torch.cat((l_pred, r_pred, pred), axis=1), (1,1,9))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d1d7b26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_loop(model, X, y, optimizer, device, scheduler, num_epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    min_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, X, y, optimizer, criterion, device)\n",
    "        train_losses.append(sum(train_loss) / len(train_loss))\n",
    "        \n",
    "        val_loss = val(model, X, y, criterion, device)\n",
    "        val_losses.append(sum(val_loss) / len(val_loss))\n",
    "        \n",
    "        print(\"Epoch: %d, train loss: %1.5f, val loss: %1.5f\" % (epoch, train_losses[epoch], \n",
    "                                                                 val_losses[epoch]))\n",
    "        if val_losses[epoch] < min_val_loss:\n",
    "            min_val_loss = val_losses[epoch]\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            #scheduler.step()\n",
    "            if counter > 10:\n",
    "                break\n",
    "        \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c554171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "lr_xyz = CustomLSTM(input_size=9).to(device)\n",
    "optimizer = torch.optim.Adam(lr_xyz.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27d21f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.79784, val loss: 0.82470\n",
      "Epoch: 1, train loss: 0.78691, val loss: 0.81353\n",
      "Epoch: 2, train loss: 0.77621, val loss: 0.80262\n",
      "Epoch: 3, train loss: 0.76577, val loss: 0.79175\n",
      "Epoch: 4, train loss: 0.75539, val loss: 0.78120\n",
      "Epoch: 5, train loss: 0.74532, val loss: 0.77069\n",
      "Epoch: 6, train loss: 0.73532, val loss: 0.76045\n",
      "Epoch: 7, train loss: 0.72559, val loss: 0.75044\n",
      "Epoch: 8, train loss: 0.71610, val loss: 0.74046\n",
      "Epoch: 9, train loss: 0.70664, val loss: 0.73081\n",
      "Epoch: 10, train loss: 0.69752, val loss: 0.72118\n",
      "Epoch: 11, train loss: 0.68843, val loss: 0.71183\n",
      "Epoch: 12, train loss: 0.67960, val loss: 0.70259\n",
      "Epoch: 13, train loss: 0.67090, val loss: 0.69350\n",
      "Epoch: 14, train loss: 0.66236, val loss: 0.68469\n",
      "Epoch: 15, train loss: 0.65408, val loss: 0.67586\n",
      "Epoch: 16, train loss: 0.64580, val loss: 0.66727\n",
      "Epoch: 17, train loss: 0.63774, val loss: 0.65875\n",
      "Epoch: 18, train loss: 0.62977, val loss: 0.65039\n",
      "Epoch: 19, train loss: 0.62195, val loss: 0.64225\n",
      "Epoch: 20, train loss: 0.61434, val loss: 0.63406\n",
      "Epoch: 21, train loss: 0.60668, val loss: 0.62607\n",
      "Epoch: 22, train loss: 0.59923, val loss: 0.61808\n",
      "Epoch: 23, train loss: 0.59178, val loss: 0.61029\n",
      "Epoch: 24, train loss: 0.58452, val loss: 0.60255\n",
      "Epoch: 25, train loss: 0.57731, val loss: 0.59481\n",
      "Epoch: 26, train loss: 0.57010, val loss: 0.58720\n",
      "Epoch: 27, train loss: 0.56303, val loss: 0.57955\n",
      "Epoch: 28, train loss: 0.55590, val loss: 0.57203\n",
      "Epoch: 29, train loss: 0.54891, val loss: 0.56449\n",
      "Epoch: 30, train loss: 0.54190, val loss: 0.55695\n",
      "Epoch: 31, train loss: 0.53489, val loss: 0.54948\n",
      "Epoch: 32, train loss: 0.52795, val loss: 0.54194\n",
      "Epoch: 33, train loss: 0.52095, val loss: 0.53446\n",
      "Epoch: 34, train loss: 0.51400, val loss: 0.52690\n",
      "Epoch: 35, train loss: 0.50698, val loss: 0.51933\n",
      "Epoch: 36, train loss: 0.49996, val loss: 0.51174\n",
      "Epoch: 37, train loss: 0.49292, val loss: 0.50411\n",
      "Epoch: 38, train loss: 0.48584, val loss: 0.49644\n",
      "Epoch: 39, train loss: 0.47873, val loss: 0.48870\n",
      "Epoch: 40, train loss: 0.47156, val loss: 0.48098\n",
      "Epoch: 41, train loss: 0.46440, val loss: 0.47310\n",
      "Epoch: 42, train loss: 0.45711, val loss: 0.46523\n",
      "Epoch: 43, train loss: 0.44983, val loss: 0.45731\n",
      "Epoch: 44, train loss: 0.44251, val loss: 0.44929\n",
      "Epoch: 45, train loss: 0.43509, val loss: 0.44119\n",
      "Epoch: 46, train loss: 0.42761, val loss: 0.43311\n",
      "Epoch: 47, train loss: 0.42016, val loss: 0.42491\n",
      "Epoch: 48, train loss: 0.41260, val loss: 0.41670\n",
      "Epoch: 49, train loss: 0.40503, val loss: 0.40845\n",
      "Epoch: 50, train loss: 0.39744, val loss: 0.40012\n",
      "Epoch: 51, train loss: 0.38978, val loss: 0.39179\n",
      "Epoch: 52, train loss: 0.38214, val loss: 0.38335\n",
      "Epoch: 53, train loss: 0.37439, val loss: 0.37498\n",
      "Epoch: 54, train loss: 0.36672, val loss: 0.36653\n",
      "Epoch: 55, train loss: 0.35899, val loss: 0.35816\n",
      "Epoch: 56, train loss: 0.35134, val loss: 0.34974\n",
      "Epoch: 57, train loss: 0.34366, val loss: 0.34136\n",
      "Epoch: 58, train loss: 0.33603, val loss: 0.33298\n",
      "Epoch: 59, train loss: 0.32841, val loss: 0.32467\n",
      "Epoch: 60, train loss: 0.32086, val loss: 0.31636\n",
      "Epoch: 61, train loss: 0.31333, val loss: 0.30815\n",
      "Epoch: 62, train loss: 0.30591, val loss: 0.30002\n",
      "Epoch: 63, train loss: 0.29857, val loss: 0.29197\n",
      "Epoch: 64, train loss: 0.29132, val loss: 0.28403\n",
      "Epoch: 65, train loss: 0.28418, val loss: 0.27618\n",
      "Epoch: 66, train loss: 0.27714, val loss: 0.26850\n",
      "Epoch: 67, train loss: 0.27027, val loss: 0.26091\n",
      "Epoch: 68, train loss: 0.26349, val loss: 0.25351\n",
      "Epoch: 69, train loss: 0.25691, val loss: 0.24625\n",
      "Epoch: 70, train loss: 0.25046, val loss: 0.23918\n",
      "Epoch: 71, train loss: 0.24419, val loss: 0.23228\n",
      "Epoch: 72, train loss: 0.23811, val loss: 0.22561\n",
      "Epoch: 73, train loss: 0.23222, val loss: 0.21911\n",
      "Epoch: 74, train loss: 0.22652, val loss: 0.21280\n",
      "Epoch: 75, train loss: 0.22100, val loss: 0.20674\n",
      "Epoch: 76, train loss: 0.21570, val loss: 0.20089\n",
      "Epoch: 77, train loss: 0.21061, val loss: 0.19527\n",
      "Epoch: 78, train loss: 0.20573, val loss: 0.18988\n",
      "Epoch: 79, train loss: 0.20106, val loss: 0.18472\n",
      "Epoch: 80, train loss: 0.19661, val loss: 0.17979\n",
      "Epoch: 81, train loss: 0.19237, val loss: 0.17508\n",
      "Epoch: 82, train loss: 0.18833, val loss: 0.17063\n",
      "Epoch: 83, train loss: 0.18452, val loss: 0.16639\n",
      "Epoch: 84, train loss: 0.18090, val loss: 0.16237\n",
      "Epoch: 85, train loss: 0.17747, val loss: 0.15860\n",
      "Epoch: 86, train loss: 0.17426, val loss: 0.15503\n",
      "Epoch: 87, train loss: 0.17124, val loss: 0.15168\n",
      "Epoch: 88, train loss: 0.16840, val loss: 0.14855\n",
      "Epoch: 89, train loss: 0.16574, val loss: 0.14561\n",
      "Epoch: 90, train loss: 0.16326, val loss: 0.14288\n",
      "Epoch: 91, train loss: 0.16095, val loss: 0.14032\n",
      "Epoch: 92, train loss: 0.15878, val loss: 0.13794\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_xyz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(model, X, y, optimizer, device, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train(model, X, y, optimizer, criterion, device)\n\u001b[0;32m      8\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28msum\u001b[39m(train_loss) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loss))\n\u001b[1;32m---> 10\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m val_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28msum\u001b[39m(val_loss) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(val_loss))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, train loss: \u001b[39m\u001b[38;5;132;01m%1.5f\u001b[39;00m\u001b[38;5;124m, val loss: \u001b[39m\u001b[38;5;132;01m%1.5f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch, train_losses[epoch], \n\u001b[0;32m     14\u001b[0m                                                          val_losses[epoch]))\n",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m, in \u001b[0;36mval\u001b[1;34m(model, X, y, criterion, device)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     11\u001b[0m     pred, hn, cn \u001b[38;5;241m=\u001b[39m model(instance, hn, cn)\n\u001b[1;32m---> 12\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(pred, y[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, j])\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6000\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\EyeTracking\\lib\\site-packages\\torch\\nn\\functional.py:4632\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(input, p, dim, eps, out)\u001b[0m\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(normalize, (\u001b[38;5;28minput\u001b[39m, out), \u001b[38;5;28minput\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, eps\u001b[38;5;241m=\u001b[39meps, out\u001b[38;5;241m=\u001b[39mout)\n\u001b[0;32m   4631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4632\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclamp_min\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_as\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m/\u001b[39m denom\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_loop(lr_xyz, X_series, y_series, optimizer, device, scheduler, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(lr_xyz.cpu(),               # model being run\n",
    "                  (X[0:1, 0:1, :], torch.zeros(1, 1, 9), torch.zeros(1, 1, 9)), # model input (or a tuple for multiple inputs)\n",
    "                  \"lr_xyz.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input', 'h0', 'c0'],   # the model's input names\n",
    "                  output_names = ['output', 'hn', 'cn']) # the model's output names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_series[:, 1:2, :]\n",
    "y = y_series[:, 1, :]\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "lr_xyz.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict, _, _ = lr_xyz(X.to(device))\n",
    "data_predict = np.array([X[0, 0, 6:9].data.numpy()])\n",
    "data_predict = np.append(data_predict, train_predict.data.cpu().numpy(), axis=0)\n",
    "\n",
    "dataY_plot = np.array([X[0, 0, 6:9].data.numpy()])\n",
    "dataY_plot = np.append(dataY_plot, y.data.numpy(), axis=0)\n",
    "print(data_predict.shape, dataY_plot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_compound = [X[0, 0, 6:9].data.numpy()]\n",
    "hn = None\n",
    "cn = None\n",
    "for i in range(X.size(0)):\n",
    "    instance = X[i:i+1]\n",
    "    pred, hn, cn = lr_xyz(instance.to(device), hn, cn)\n",
    "    pred = nn.functional.normalize(pred)\n",
    "    pred = pred.data.cpu().numpy()\n",
    "    cur = X[i, 0, 6:9].data.numpy()\n",
    "    data_compound.append(pred[0])\n",
    "    if i < X.size(0) - 1:\n",
    "        X[i+1,0,0:3] = nn.functional.normalize(torch.reshape(X[i+1,0,6:9] + X[i+1,0,0:3] - torch.Tensor(pred[0]), (1,3))).view(-1,3)\n",
    "        X[i+1,0,3:6] = nn.functional.normalize(torch.reshape(X[i+1,0,6:9] + X[i+1,0,3:6] - torch.Tensor(pred[0]), (1,3))).view(-1,3)\n",
    "        X[i+1,0,6] = pred[0,0].item()\n",
    "        X[i+1,0,7] = pred[0,1].item()\n",
    "        X[i+1,0,8] = pred[0,2].item()\n",
    "data_compound = np.array(data_compound)\n",
    "print(data_compound.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b7549",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.axvline(x=6000, c='r', linestyle=\"--\")\n",
    "\n",
    "plt.plot(dataY_plot[:, 0], label=\"Actual Data\")\n",
    "#plt.plot(data_predict[:, 0], label=\"Predicted Data\")\n",
    "plt.plot(data_compound[:, 0], label=\"Compounded Data\")\n",
    "plt.title(\"Neck Prediction X\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6080e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.axvline(x=6000, c='r', linestyle=\"--\")\n",
    "\n",
    "plt.plot(dataY_plot[:, 1], label=\"Actual Data\")\n",
    "#plt.plot(data_predict[:, 1], label=\"Predicted Data\")\n",
    "plt.plot(data_compound[:, 1], label=\"Compounded Data\")\n",
    "plt.title(\"Neck Prediction Y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.axvline(x=6000, c='r', linestyle=\"--\")\n",
    "\n",
    "plt.plot(dataY_plot[:, 2], label=\"Actual Data\")\n",
    "#plt.plot(data_predict[:, 2], label=\"Predicted Data\")\n",
    "plt.plot(data_compound[:, 2], label=\"Compounded Data\")\n",
    "plt.title(\"Neck Prediction Z\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd8a6c",
   "metadata": {},
   "source": [
    "## Testing on New Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../EyeTrackingTest/Data/Test/1_0.txt\", delimiter=\",\").iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f401faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelx = []\n",
    "labely = []\n",
    "labelz = []\n",
    "for i in range(df.shape[0] - 1):\n",
    "    label_row = df.iloc[i + 1]\n",
    "    labelx.append(label_row[\"forward.x\"])\n",
    "    labely.append(label_row[\"forward.y\"])\n",
    "    labelz.append(label_row[\"forward.z\"])\n",
    "    \n",
    "df = df.iloc[:-1, :]\n",
    "df[\"label.x\"] = labelx\n",
    "df[\"label.y\"] = labely\n",
    "df[\"label.z\"] = labelz\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775705bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 3:-3].to_numpy()\n",
    "y = df.iloc[:, -3:].to_numpy()\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd127a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Variable(torch.Tensor(X))\n",
    "y = Variable(torch.Tensor(y))\n",
    "\n",
    "X = torch.reshape(X, (X.shape[0], 1, X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c939ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict, _, _ = lr_xyz(X.to(device))\n",
    "data_predict = train_predict.data.cpu().numpy()\n",
    "dataY_plot = y.data.numpy()\n",
    "\n",
    "data_compound = [X[0, 0, 6:9].data.numpy()]\n",
    "hn = None\n",
    "cn = None\n",
    "for i in range(X.size(0)):\n",
    "    instance = X[i:i+1]\n",
    "    pred, hn, cn = lr_xyz(instance.to(device), hn, cn)\n",
    "    pred = pred.data.cpu().numpy()\n",
    "    cur = X[i, 0, 6:9].data.numpy()\n",
    "    data_compound.append(pred[0])\n",
    "    if i < X.size(0) - 1:\n",
    "        X[i+1,0,0:3] = nn.functional.normalize(torch.reshape(X[i+1,0,6:9] + X[i+1,0,0:3] - torch.Tensor(pred[0]), (1,3))).view(-1,3)\n",
    "        X[i+1,0,3:6] = nn.functional.normalize(torch.reshape(X[i+1,0,6:9] + X[i+1,0,3:6] - torch.Tensor(pred[0]), (1,3))).view(-1,3)\n",
    "        X[i+1,0,6] = pred[0,0].item()\n",
    "        X[i+1,0,7] = pred[0,1].item()\n",
    "        X[i+1,0,8] = pred[0,2].item()\n",
    "data_compound = np.array(data_compound)\n",
    "print(data_compound.shape)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(dataY_plot[:, 0], label=\"Actual Data\")\n",
    "plt.plot(data_compound[:, 0], label=\"Predicted Data\")\n",
    "plt.title(\"Neck Prediction X\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(dataY_plot[:, 1], label=\"Actual Data\")\n",
    "plt.plot(data_compound[:, 1], label=\"Predicted Data\")\n",
    "plt.title(\"Neck Prediction Y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a964491",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(dataY_plot[:, 2], label=\"Actual Data\")\n",
    "plt.plot(data_compound[:, 2], label=\"Predicted Data\")\n",
    "plt.title(\"Neck Prediction Z\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d7580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da105144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
